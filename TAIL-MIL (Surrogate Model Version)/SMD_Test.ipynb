{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00010a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import *\n",
    "from TAILMIL import *\n",
    "import os\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "preprocessed_path = 'SMD/preprocessed_set/'\n",
    "interpretation_path = 'SMD/interpretation_label/'\n",
    "\n",
    "x_train_path = [preprocessed_path + t for t in sorted(os.listdir(preprocessed_path)) if 'train' in t]\n",
    "x_test_path = [preprocessed_path + t for t in sorted(os.listdir(preprocessed_path)) if 'test.' in t]\n",
    "y_test_path = [preprocessed_path + t for t in sorted(os.listdir(preprocessed_path)) if 'test_' in t]\n",
    "y_test_label = [interpretation_path + t for t in sorted(os.listdir(interpretation_path)) if 'machine' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a60401",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in tqdm_notebook(range(11)):\n",
    "    f = open(x_train_path[ii], \"rb\")\n",
    "    x_train = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    f = open(x_test_path[ii], \"rb\")\n",
    "    x_test = pickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    f = open(y_test_path[ii], \"rb\")\n",
    "    y_test = pickle.load(f).reshape((-1))\n",
    "    f.close()\n",
    "\n",
    "    f = open(y_test_label[ii], 'r')     # mode = 부분은 생략해도 됨\n",
    "    lines= f.read()\n",
    "    f.close()\n",
    "\n",
    "    print('-------------------------------------------------------------')\n",
    "    print(x_train_path[ii].split('/')[-1][:-4])\n",
    "\n",
    "    y_interpretated_label = np.zeros(x_train.shape)\n",
    "\n",
    "    start_indexes = []\n",
    "    end_indexes = []\n",
    "    i_labels = []\n",
    "\n",
    "    for info in lines.split('\\n')[:-1]:\n",
    "        pattern = r'(\\d+)-(\\d+):([\\d,]+)'\n",
    "        match = re.match(pattern, info)\n",
    "        if match:\n",
    "            start_index = int(match.group(1))\n",
    "            end_index = int(match.group(2))\n",
    "            columns_to_label = list(map(int, match.group(3).split(',')))\n",
    "\n",
    "            # 해당 인덱스와 컬럼에 1로 라벨링합니다.\n",
    "            y_interpretated_label[start_index:end_index + 1, columns_to_label] = 1\n",
    "            start_indexes.append(start_index)\n",
    "            end_indexes.append(end_index)\n",
    "            i_labels.append(columns_to_label)\n",
    "\n",
    "    x_train, scaler = normalize_data(x_train, scaler=None)\n",
    "    x_test, _ = normalize_data(x_test, scaler=scaler)\n",
    "\n",
    "    # print('Data Size')\n",
    "    # print(x_train.shape, x_test.shape, y_test.shape, y_interpretated_label.shape)\n",
    "\n",
    "    n_features = x_train.shape[1]\n",
    "    window_size, target_dims = 12, x_train.shape[1]\n",
    "    out_dim = 1\n",
    "    batch_size, val_split, shuffle_dataset = 128, 0.2, True\n",
    "\n",
    "    train_dataset = SlidingWindowDataset(x_train, window_size, target_dims)\n",
    "    test_dataset = SlidingWindowDataset(x_test, window_size, target_dims)\n",
    "\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        train_dataset, batch_size, val_split, shuffle_dataset, test_dataset=test_dataset\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "    model = MTAD_GAT_RECON(\n",
    "        n_features,\n",
    "        window_size,\n",
    "        n_features,\n",
    "        kernel_size=7,\n",
    "        use_gatv2=True,\n",
    "        feat_gat_embed_dim=None,\n",
    "        time_gat_embed_dim=None,\n",
    "        gru_n_layers=1,\n",
    "        gru_hid_dim=300,\n",
    "        recon_n_layers=1,\n",
    "        recon_hid_dim=300,\n",
    "        dropout=0.3,\n",
    "        alpha=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    save_path = 'Model/' + x_train_path[ii].split('/')[-1][:-4]+'.p'\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "    x_train_new = []\n",
    "    y_train = []\n",
    "\n",
    "    model.eval()\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = model(x)\n",
    "\n",
    "        x_train_new.append(x.detach().cpu().numpy())\n",
    "        y_train.append((y_hat - y).detach().cpu().numpy()**2)\n",
    "\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "    y_train = y_train.sum(2).sum(1)\n",
    "    percentile_95 = np.percentile(y_train, 50)\n",
    "\n",
    "    # y_train[y_train<percentile_95] = 0\n",
    "\n",
    "    x_train_new = np.concatenate(x_train_new, axis=0)\n",
    "\n",
    "    x_valid_new = []\n",
    "    y_valid = []\n",
    "\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat = model(x)\n",
    "\n",
    "        x_valid_new.append(x.detach().cpu().numpy())\n",
    "        y_valid.append((y_hat - y).detach().cpu().numpy()**2)\n",
    "\n",
    "    y_valid = np.concatenate(y_valid, axis=0)\n",
    "    y_valid = y_valid.sum(2).sum(1)\n",
    "    # y_valid[y_valid<percentile_95] = 0\n",
    "    x_valid_new = np.concatenate(x_valid_new, axis=0)\n",
    "\n",
    "    trainset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(x_train_new), \n",
    "        torch.FloatTensor(y_train), \n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size = 1020,\n",
    "        shuffle = True\n",
    "    )\n",
    "\n",
    "    validset = torch.utils.data.TensorDataset(\n",
    "        torch.FloatTensor(x_valid_new), \n",
    "        torch.FloatTensor(y_valid),\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        validset,\n",
    "        batch_size = 512,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    max_grad_norm = 0.9\n",
    "\n",
    "    milnet = TAILMIL(window=12, dim=38, sub_window=1).to(device)\n",
    "    optimizer = torch.optim.AdamW(milnet.parameters(), 1e-2)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    best_loss_path2 = f\"{x_train_path[ii].split('/')[-1][:-4]}_TAILMIL.p\"\n",
    "\n",
    "    best_mse = 999\n",
    "\n",
    "    train_auc = []\n",
    "    valid_auc = []\n",
    "\n",
    "    for e in tqdm_notebook(range(1, int(20)+1)):\n",
    "        train_output = []\n",
    "        train_label = []\n",
    "\n",
    "        valid_output = []\n",
    "        valid_label = []\n",
    "\n",
    "        milnet.train()\n",
    "        for batch_id, (x, label) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            label = label.float().to(device)\n",
    "            x = x.transpose(1, 2).to(device)\n",
    "            out, _, _ = milnet(x)\n",
    "            loss = loss_fn(out, label.reshape(out.shape))\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(milnet.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            temp_out = out.detach().cpu().numpy()\n",
    "            temp_label = label.detach().cpu().numpy()\n",
    "            train_output += list(temp_out)\n",
    "            train_label += list(temp_label)\n",
    "\n",
    "    #     if e%10 ==0 or e ==1:\n",
    "    #         print(f'-----------------------------------------------{e} Train END--------------------------------------------')\n",
    "    #         print(f'ROC-AUC score: {roc_auc_score(np.array(train_label)>0.2, np.array(train_output).reshape(-1))}')\n",
    "    #         print(f'MSE score: {mean_squared_error(np.array(train_label), np.array(train_output).reshape(-1))}')\n",
    "\n",
    "        train_auc.append(roc_auc_score(np.array(train_label)>percentile_95, np.argmax(train_output, axis=1)))\n",
    "\n",
    "        milnet.eval()\n",
    "        for batch_id, (x, label) in enumerate(valid_loader):   \n",
    "            label = label.float().to(device)\n",
    "            x = x.transpose(1, 2).to(device)\n",
    "            out, _, _ = milnet(x)\n",
    "\n",
    "            temp_out = out.detach().cpu().numpy()\n",
    "            temp_label = label.detach().cpu().numpy()\n",
    "            valid_output += list(temp_out)\n",
    "            valid_label += list(temp_label)\n",
    "\n",
    "    #     if e%10 == 0 or e ==1:\n",
    "    #         print(f'-----------------------------------------------{e} Validation--------------------------------------------')\n",
    "    #         print(f'ROC-AUC score: {roc_auc_score(np.array(valid_label)>0.2, np.array(valid_output).reshape(-1))}')\n",
    "    #         print(f'MSE score: {mean_squared_error(np.array(valid_label), np.array(valid_output).reshape(-1))}')\n",
    "\n",
    "        valid_auc.append(roc_auc_score(np.array(valid_label)>percentile_95, np.array(valid_output).reshape(-1)))\n",
    "\n",
    "    #     if best_f1 < roc_auc_score(np.array(valid_label)>0.2, np.array(valid_output).reshape(-1)):\n",
    "    #         best_f1 = roc_auc_score(np.array(valid_label)>0.2, np.array(valid_output).reshape(-1))\n",
    "    #         torch.save(calmilnet.state_dict(), best_loss_path1)\n",
    "\n",
    "        if best_mse > mean_squared_error(np.array(valid_label), np.array(valid_output).reshape(-1)):\n",
    "            best_f1 = mean_squared_error(np.array(valid_label), np.array(valid_output).reshape(-1))\n",
    "            torch.save(milnet.state_dict(), best_loss_path2)\n",
    "\n",
    "    milnet.load_state_dict(torch.load(best_loss_path2))\n",
    "\n",
    "    sliding_window_label = []\n",
    "\n",
    "    for i in range(len(y_test)-12):\n",
    "        if sum(y_test[i:i+12]) > 0:\n",
    "            sliding_window_label.append(1)\n",
    "        else:\n",
    "            sliding_window_label.append(0)\n",
    "\n",
    "    sliding_window_label = np.array(sliding_window_label)\n",
    "\n",
    "    recons = []\n",
    "    recons2 = []\n",
    "    preds = []\n",
    "\n",
    "    milnet.eval()\n",
    "    for x, y in test_loader:\n",
    "        x = x.transpose(1, 2).to(device)\n",
    "        y = y.to(device)\n",
    "        y_hat, y_hat2, y_hat3 = milnet(x)\n",
    "\n",
    "        recons.append(y_hat.detach().cpu().numpy())\n",
    "        recons2.append(y_hat2[:, -1].detach().cpu().numpy())\n",
    "        preds.append(y_hat3.detach().cpu().numpy())\n",
    "\n",
    "    recons = np.concatenate(recons, axis=0)\n",
    "    recons2 = np.concatenate(recons2, axis=0)\n",
    "    recons2 = recons2.reshape(-1)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "    print('Slinding Window Performance')\n",
    "    print(f'AUROC: {roc_auc_score(sliding_window_label, recons)}')\n",
    "    print(f'AUPR: {average_precision_score(sliding_window_label, recons)}')\n",
    "\n",
    "    print('One Step Performance')\n",
    "    print(f'AUROC: {roc_auc_score(y_test[12:], recons2)}')\n",
    "    print(f'AUPR: {average_precision_score(y_test[12:], recons2)}')\n",
    "\n",
    "    corrects = []\n",
    "    for i in range(len(start_indexes)):\n",
    "        temp_preds = preds.reshape(-1, 38)[start_indexes[i]:end_indexes[i]].argmax(1)\n",
    "        for j in range(len(temp_preds)):\n",
    "            if temp_preds[j] in i_labels[i]:\n",
    "                corrects.append(1)\n",
    "            else:\n",
    "                corrects.append(0)\n",
    "\n",
    "    print('Interpretation Performance')\n",
    "    print(f'ACC: {sum(corrects) / len(corrects)}')\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039966a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
